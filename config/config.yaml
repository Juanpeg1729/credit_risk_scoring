# config/config.yaml

data:
  path: "data/german.data"
  target_col: "Risk"
  test_size: 0.2
  random_state: 42

model:
  name: "xgboost"
  params:
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
    subsample: 0.8 
    colsample_bytree: 0.8 # Esto sirve para evitar overfitting. Funciona similar al dropout en redes neuronales.
    n_jobs: -1

mlflow:
  experiment_name: "Adult_Income_Engineering"
