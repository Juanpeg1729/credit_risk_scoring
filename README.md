# ğŸ¯ Adult Income Prediction (End-to-End MLOps Pipeline)

![Python Version](https://img.shields.io/badge/python-3.12-blue)
![Docker](https://img.shields.io/badge/docker-enabled-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-ready-009688)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-in--progress-yellow)

Este proyecto desarrolla un flujo de trabajo completo (**End-to-End MLOps**) para predecir si una persona gana mÃ¡s de $50,000 anuales basÃ¡ndose en datos demogrÃ¡ficos y laborales.

El enfoque principal de este repositorio es presentar una **arquitectura de software de Machine Learning robusta, modular y desplegable**, integrando las mejores prÃ¡cticas de la industria para garantizar la reproducibilidad y escalabilidad. AdemÃ¡s, se lleva a cabo un flujo de trabajo de machine learning profesional, desde la limpieza de datos hasta la selecciÃ³n de modelos mediante **ValidaciÃ³n Cruzada Anidada (NCV)** para obtener una estimaciÃ³n de rendimiento imparcial.

---

## ğŸ“‹ Tabla de Contenidos
- [Arquitectura y Tech Stack](#-arquitectura-y-tech-stack)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [InstalaciÃ³n y Uso (Docker & Local)](#-instalaciÃ³n-y-uso)
- [API de PredicciÃ³n](#-api-de-predicciÃ³n)
- [MetodologÃ­a de ML](#-metodologÃ­a-de-ml)
- [Resultados del Modelo](#-resultados-del-modelo)
- [Autor](#-autor)

---

## ğŸ›  Arquitectura y Tech Stack

Este proyecto va mÃ¡s allÃ¡ del modelado tradicional, implementando un ciclo de vida completo:

* **Lenguaje:** Python 3.11
* **GestiÃ³n de Dependencias:** [uv](https://github.com/astral-sh/uv) (Ultra-rÃ¡pido y moderno).
* **ConfiguraciÃ³n:** [Hydra](https://hydra.cc/) (GestiÃ³n de hiperparÃ¡metros centralizada vÃ­a YAML).
* **Modelado:** XGBoost + Scikit-Learn (Pipelines avanzados).
* **OptimizaciÃ³n:** [Optuna](https://optuna.org/) (Ajuste bayesiano de hiperparÃ¡metros).
* **Tracking:** [MLflow](https://mlflow.org/) (Registro de experimentos y mÃ©tricas).
* **Despliegue (Serving):** FastAPI + Pydantic (API REST de alto rendimiento).
* **ContenedorizaciÃ³n:** Docker (Entorno aislado y reproducible).

---

## ğŸ“‚ Estructura del Proyecto

Se sigue una estructura de paquete modular:

```text
.
â”œâ”€â”€ config/             # ConfiguraciÃ³n centralizada (Hydra)
â”‚   â””â”€â”€ config.yaml     # HiperparÃ¡metros y rutas
â”œâ”€â”€ data/               # Dataset (adult.csv)
â”œâ”€â”€ docker/             # Archivos auxiliares de Docker
â”œâ”€â”€ notebooks/          # EDA y experimentaciÃ³n inicial (Legacy)
â”œâ”€â”€ src/                # CÃ³digo fuente modular
â”‚   â”œâ”€â”€ api.py          # Endpoint de inferencia (FastAPI)
â”‚   â”œâ”€â”€ pipeline.py     # ConstrucciÃ³n del modelo y Sklearn Pipelines
â”‚   â”œâ”€â”€ preprocessing.py# Limpieza e ingenierÃ­a de datos robusta
â”‚   â””â”€â”€ train.py        # Script maestro de entrenamiento y serializaciÃ³n
â”œâ”€â”€ Dockerfile          # DefiniciÃ³n de la imagen de producciÃ³n
â”œâ”€â”€ pyproject.toml      # Dependencias del proyecto (uv)
â””â”€â”€ README.md           # DocumentaciÃ³n
``` 

---

## ğŸ’» InstalaciÃ³n y Uso

Tienes dos formas de ejecutar este proyecto: la Profesional (Docker) y la de Desarrollo (Local).


**OpciÃ³n A: Usando Docker (Recomendado)**

No necesitas instalar Python ni librerÃ­as, solo Docker. Garantiza que funcione igual en cualquier mÃ¡quina. 

1. **Construir la imagen:** Descarga dependencias, entrena el modelo y prepara la API automÃ¡ticamente.

```bash
docker build -t adult-income-app .
```

2. **Ejecutar el contenedor:**

```
docker run -p 8000:8000 adult-income-app
```

3. **Acceder:** abre tu navegador en http://localhost:8000/docs


**OpciÃ³n B: EjecuciÃ³n Local (Desarrollo)**

Si deseas editar el cÃ³digo o entrenar manualmente. Requisito: tener uv instalado.

1. **Instalar dependencias:**

```
uv sync
```

2. **Entrenar el modelo (Pipeline completo):** Ejecuta la limpieza, validaciÃ³n y entrenamiento.

```
uv run python -m src.train
```

3. **Levantar la API:**

```
uv run uvicorn src.api:app --reload
```

---

## ğŸ§ª API de PredicciÃ³n

El proyecto incluye una API REST documentada automÃ¡ticamente con Swagger UI.

- **Endpoint:** `/predict` (POST)  
- **Input:** JSON con datos demogrÃ¡ficos (edad, educaciÃ³n, ocupaciÃ³n, etc.).  
- **Output:** PredicciÃ³n de clase (`<=50K` o `>50K`) y probabilidad de confianza.

**Ejemplo de uso (Swagger UI):** *(Imagen referencial de la interfaz que verÃ¡s al lanzar el proyecto)*

---

## ğŸ§  MetodologÃ­a de ML

Aunque el cÃ³digo ahora es modular, la lÃ³gica de Machine Learning subyacente se mantiene sÃ³lida:

1. **IngenierÃ­a de Datos:**
   - Saneamiento de errores de formato (ej. valores corruptos como `5E-1`).
   - ImputaciÃ³n de nulos y eliminaciÃ³n de duplicados.

2. **Pipeline de Preprocesamiento:**
   - `ColumnTransformer` para aplicar escalado (`StandardScaler`) a numÃ©ricas y One-Hot Encoding a categÃ³ricas.

3. **SelecciÃ³n de Modelos:**
   - Se utilizÃ³ **ValidaciÃ³n Cruzada Anidada (Nested CV)** para comparar XGBoost, Random Forest y RegresiÃ³n LogÃ­stica sin sesgo.

4. **OptimizaciÃ³n:**
   - Se implementÃ³ **Optuna** para el ajuste fino (fine-tuning) de hiperparÃ¡metros del modelo ganador.

---

## ğŸ“Š Resultados del Modelo

Tras la evaluaciÃ³n rigurosa, **XGBoost** fue seleccionado como el modelo de producciÃ³n por su capacidad para manejar desbalanceo y relaciones no lineales.

| Modelo               | F1-Score Medio (NCV) | DesviaciÃ³n |
|---------------------|-----------------------|------------|
| **XGBoost (Optimizado)** | **0.7220**              | +/- 0.008  |
| Random Forest       | 0.6785                | +/- 0.012  |
| RegresiÃ³n LogÃ­stica | 0.6565                | +/- 0.008  |

---

## âœ’ï¸ Autor

**Juan Pedro GarcÃ­a Sanz**

* **GitHub:** [@Juan Pedro GarcÃ­a Sanz](https://github.com/Juanpeg1729)
* **LinkedIn:** [linkedin.com/in/juan-pedro-garcÃ­a-sanz-443b31343](https://www.linkedin.com/in/juan-pedro-garcÃ­a-sanz-443b31343)
