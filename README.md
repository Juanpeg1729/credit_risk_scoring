# ğŸ¦ Credit Risk Scoring: End-to-End MLOps Pipeline

![Python Version](https://img.shields.io/badge/python-3.11-blue)
![Docker](https://img.shields.io/badge/docker-enabled-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-ready-009688)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=Streamlit&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-green)

Este proyecto desarrolla un flujo de trabajo completo (**End-to-End MLOps**) para la evaluaciÃ³n de riesgo crediticio. El sistema predice la probabilidad de impago de un cliente basÃ¡ndose en su perfil financiero y demogrÃ¡fico, utilizando datos del mercado alemÃ¡n.

El enfoque principal de este repositorio es presentar una **arquitectura de software de Machine Learning robusta, modular y desplegable**, integrando las mejores prÃ¡cticas de la industria para garantizar la reproducibilidad y escalabilidad. AdemÃ¡s, se lleva a cabo un flujo de trabajo de machine learning profesional, desde la limpieza de datos y la selecciÃ³n de modelos mediante **ValidaciÃ³n Cruzada Anidada (NCV)** hasta el despliegue en contenedores Docker con interfaces de consumo (API) y explicabilidad (XAI).

---

## ğŸ“‹ Tabla de Contenidos
- [Arquitectura y Tech Stack](#-arquitectura-y-tech-stack)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [AutomatizaciÃ³n (Makefile)](#-automatizaciÃ³n-makefile)
- [InstalaciÃ³n y Uso](#-instalaciÃ³n-y-uso)
- [Dashboard & Interpretabilidad](#-dashboard--interpretabilidad-xai)
- [MetodologÃ­a de ML](#-metodologÃ­a-de-ml)
- [Resultados del Modelo](#-resultados-del-modelo)
- [Autor](#-autor)

---

## ğŸ›  Arquitectura y Tech Stack

El proyecto integra herramientas modernas para crear un sistema robusto, modular y escalable:

* **Lenguaje:** Python 3.11
* **GestiÃ³n de Dependencias:** [uv](https://github.com/astral-sh/uv) (Gestor de paquetes de alto rendimiento).
* **AutomatizaciÃ³n:** **GNU Make** (OrquestaciÃ³n de comandos).
* **ConfiguraciÃ³n:** [Hydra](https://hydra.cc/) (GestiÃ³n de hiperparÃ¡metros vÃ­a YAML).
* **Modelado:** XGBoost + Scikit-Learn (Pipelines de preprocesamiento).
* **OptimizaciÃ³n:** [Optuna](https://optuna.org/) (Ajuste bayesiano de hiperparÃ¡metros).
* **Interpretabilidad (XAI):** [SHAP](https://shap.readthedocs.io/) (ExplicaciÃ³n de predicciones "Caja Negra").
* **Interfaces:** * **FastAPI:** API REST para inferencia mÃ¡quina-a-mÃ¡quina.
    * **Streamlit:** Dashboard interactivo para usuarios de negocio.
* **Infraestructura:** Docker (ContenedorizaciÃ³n completa).

---

## ğŸ“‚ Estructura del Proyecto

El cÃ³digo sigue una arquitectura de paquete modular, separando configuraciÃ³n, lÃ³gica y presentaciÃ³n:

```text
.
â”œâ”€â”€ config/             # âš™ï¸ ConfiguraciÃ³n centralizada (Hydra)
â”œâ”€â”€ data/               # ğŸ’¾ Datos crudos (German Credit Data)
â”œâ”€â”€ docker/             # ğŸ³ Archivos auxiliares de Docker
â”œâ”€â”€ src/                # ğŸ§  CÃ³digo fuente
â”‚   â”œâ”€â”€ api.py          # API con FastAPI
â”‚   â”œâ”€â”€ dashboard.py    # Interfaz Web con Streamlit + SHAP
â”‚   â”œâ”€â”€ pipeline.py     # DefiniciÃ³n del modelo y transformadores
â”‚   â”œâ”€â”€ preprocessing.py# Limpieza e ingenierÃ­a de datos
â”‚   â””â”€â”€ train.py        # Script de entrenamiento y serializaciÃ³n
â”œâ”€â”€ Dockerfile          # Receta de la imagen de producciÃ³n
â”œâ”€â”€ Makefile            # ğŸ•¹ï¸ Comandos de automatizaciÃ³n
â”œâ”€â”€ pyproject.toml      # Dependencias
â””â”€â”€ README.md           # DocumentaciÃ³n
``` 

---

## ğŸ•¹ï¸ AutomatizaciÃ³n (Makefile)

Para facilitar el uso, el proyecto incluye un Makefile que abstrae los comandos complejos.

```bash
make install	Instala las dependencias con uv.
make train	Ejecuta el pipeline de entrenamiento completo.
make api	Levanta el servidor de la API (FastAPI) en local.
make dashboard	Lanza la aplicaciÃ³n web (Streamlit).
make docker-build	Construye la imagen de Docker.
make docker-run	Ejecuta el contenedor con la App completa.
```

---

## ğŸ’» InstalaciÃ³n y Uso

Tienes dos formas de ejecutar este proyecto: la Profesional (Docker) y la de Desarrollo (Local).


**OpciÃ³n A: Usando Docker (Recomendado)**

No necesitas instalar Python ni librerÃ­as, solo Docker. Garantiza que funcione igual en cualquier mÃ¡quina. 

1. **Construir y ejecutar:**

```bash
make docker-build
make docker run
```

2. **Ejecutar el contenedor:**

```
docker run -p 8000:8000 adult-income-app
```

3. **Acceder:** abre tu navegador en http://localhost:8000/docs


**OpciÃ³n B: EjecuciÃ³n Local (Desarrollo)**

Si deseas editar el cÃ³digo o entrenar manualmente. Requisito: tener uv instalado.

1. **Instalar dependencias:**

```
uv sync
```

2. **Entrenar el modelo (Pipeline completo):** Ejecuta la limpieza, validaciÃ³n y entrenamiento.

```
uv run python -m src.train
```

3. **Levantar la API:**

```
uv run uvicorn src.api:app --reload
```

---

## ğŸ§ª API de PredicciÃ³n

El proyecto incluye una API REST documentada automÃ¡ticamente con Swagger UI.

- **Endpoint:** `/predict` (POST)  
- **Input:** JSON con datos demogrÃ¡ficos (edad, educaciÃ³n, ocupaciÃ³n, etc.).  
- **Output:** PredicciÃ³n de clase (`<=50K` o `>50K`) y probabilidad de confianza.

**Ejemplo de uso (Swagger UI):** *(Imagen referencial de la interfaz que verÃ¡s al lanzar el proyecto)*

---

## ğŸ§  MetodologÃ­a de ML

Aunque el cÃ³digo ahora es modular, la lÃ³gica de Machine Learning subyacente se mantiene sÃ³lida:

1. **IngenierÃ­a de Datos:**
   - Saneamiento de errores de formato (ej. valores corruptos como `5E-1`).
   - ImputaciÃ³n de nulos y eliminaciÃ³n de duplicados.

2. **Pipeline de Preprocesamiento:**
   - `ColumnTransformer` para aplicar escalado (`StandardScaler`) a numÃ©ricas y One-Hot Encoding a categÃ³ricas.

3. **SelecciÃ³n de Modelos:**
   - Se utilizÃ³ **ValidaciÃ³n Cruzada Anidada (Nested CV)** para comparar XGBoost, Random Forest y RegresiÃ³n LogÃ­stica sin sesgo.

4. **OptimizaciÃ³n:**
   - Se implementÃ³ **Optuna** para el ajuste fino (fine-tuning) de hiperparÃ¡metros del modelo ganador.

---

## ğŸ“Š Resultados del Modelo

Tras la evaluaciÃ³n rigurosa, **XGBoost** fue seleccionado como el modelo de producciÃ³n por su capacidad para manejar desbalanceo y relaciones no lineales.

| Modelo               | F1-Score Medio (NCV) | DesviaciÃ³n |
|---------------------|-----------------------|------------|
| **XGBoost (Optimizado)** | **0.7220**              | +/- 0.008  |
| Random Forest       | 0.6785                | +/- 0.012  |
| RegresiÃ³n LogÃ­stica | 0.6565                | +/- 0.008  |

---

## âœ’ï¸ Autor

**Juan Pedro GarcÃ­a Sanz**

* **GitHub:** [@Juan Pedro GarcÃ­a Sanz](https://github.com/Juanpeg1729)
* **LinkedIn:** [linkedin.com/in/juan-pedro-garcÃ­a-sanz-443b31343](https://www.linkedin.com/in/juan-pedro-garcÃ­a-sanz-443b31343)
