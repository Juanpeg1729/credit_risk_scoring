# ğŸ¦ Credit Risk Scoring con Machine Learning

![Status](https://img.shields.io/badge/status-production-green)
![Python Version](https://img.shields.io/badge/python-3.11-blue)
![uv](https://img.shields.io/badge/uv-enabled-purple)
![Docker](https://img.shields.io/badge/docker-enabled-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-ready-009688)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=Streamlit&logoColor=white)

Este proyecto implementa un sistema completo para evaluar el riesgo crediticio usando Machine Learning. El modelo analiza el perfil financiero de un cliente y predice automÃ¡ticamente la probabilidad de impago.

El sistema incluye tracking de experimentos con MLflow, explicabilidad con SHAP, una API REST para predicciones y un dashboard interactivo, todo desplegable con Docker.

---

## ğŸ“‹ Tabla de Contenidos

- [Arquitectura y Tech Stack](#-arquitectura-y-tech-stack)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [AutomatizaciÃ³n (Makefile)](#%EF%B8%8F-automatizaciÃ³n-makefile)
- [InstalaciÃ³n y Uso](#-instalaciÃ³n-y-uso)
- [Dashboard & API](#-dashboard--api)
- [MetodologÃ­a de Data Science](#-metodologÃ­a-de-data-science)
- [Resultados](#-resultados)
- [Autor](#-autor)

---

## ğŸ›  Arquitectura y Tech Stack

El proyecto utiliza tecnologÃ­as modernas para crear un sistema robusto y escalable:

* **Lenguaje:** Python 3.11
* **GestiÃ³n de Dependencias:** [uv](https://github.com/astral-sh/uv) - Gestor de paquetes de alto rendimiento
* **ConfiguraciÃ³n:** [Hydra](https://hydra.cc/) - GestiÃ³n de configuraciÃ³n mediante YAML
* **Modelo de ML:** 
    * **XGBoost:** Modelo de Gradient Boosting
    * **Scikit-Learn:** Pipelines de preprocesamiento
    * **Optuna:** OptimizaciÃ³n de hiperparÃ¡metros
* **Tracking:** MLflow - Registro de experimentos y modelos
* **Interpretabilidad:** [SHAP](https://shap.readthedocs.io/) - Explicaciones visuales de predicciones
* **Interfaces:** 
    * **FastAPI:** API REST para predicciones
    * **Streamlit:** Dashboard interactivo con explicabilidad
* **Despliegue:** Docker y Docker Compose

---

## ğŸ“‚ Estructura del Proyecto

El cÃ³digo estÃ¡ organizado en mÃ³dulos separados para facilitar el mantenimiento:

```text
.
â”œâ”€â”€ config/              # ConfiguraciÃ³n (Hydra YAML)
â”‚   â””â”€â”€ config.yaml      # ParÃ¡metros del modelo y datos
â”œâ”€â”€ data/                # Dataset (German Credit Data)
â”œâ”€â”€ images/              # GrÃ¡ficos y visualizaciones
â”œâ”€â”€ mlruns/              # Experimentos MLflow
â”œâ”€â”€ notebooks/           # AnÃ¡lisis exploratorio e interpretabilidad
â”œâ”€â”€ src/                 # CÃ³digo fuente
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py           # API REST (FastAPI)
â”‚   â”œâ”€â”€ dashboard.py     # Dashboard interactivo (Streamlit)
â”‚   â”œâ”€â”€ pipeline.py      # Pipeline de ML
â”‚   â”œâ”€â”€ preprocessing.py # Limpieza de datos
â”‚   â””â”€â”€ train.py         # Entrenamiento con MLflow
â”œâ”€â”€ .dockerignore        # Archivos excluidos de Docker
â”œâ”€â”€ .gitignore           # Archivos excluidos de Git
â”œâ”€â”€ docker-compose.yml   # ConfiguraciÃ³n de contenedores
â”œâ”€â”€ Dockerfile           # Imagen de Docker
â”œâ”€â”€ Makefile             # Comandos simplificados
â”œâ”€â”€ pyproject.toml       # Dependencias del proyecto
â”œâ”€â”€ uv.lock              # Versiones exactas de dependencias
â””â”€â”€ README.md            # DocumentaciÃ³n
```

---

## ğŸ•¹ï¸ AutomatizaciÃ³n (Makefile)

El proyecto incluye comandos simplificados para facilitar su uso:

| Comando | DescripciÃ³n |
| :--- | :--- |
| `make help` | Muestra todos los comandos disponibles |
| `make install` | Instala las dependencias del proyecto |
| `make api` | Inicia el servidor API en local |
| `make dashboard` | Inicia el dashboard interactivo |
| `make docker-build` | Construye las imÃ¡genes de Docker |
| `make docker-up` | Inicia todo el sistema con Docker |
| `make docker-down` | Detiene todos los contenedores |
| `make clean` | Limpia archivos temporales y cachÃ© |

---

## ğŸ’» InstalaciÃ³n y Uso

### OpciÃ³n A: Docker (Recomendada)

1. **Inicia el sistema completo:**

    ```bash
    make docker-up
    ```

    La primera vez puede tardar unos minutos mientras descarga las imÃ¡genes.

2. **Acceder a las interfaces:**

    * Dashboard: http://localhost:8501
    * API: http://localhost:8000/docs

3. **Detener el sistema:**

    ```bash
    make docker-down
    ```

### OpciÃ³n B: EjecuciÃ³n Local

Para desarrollo o si prefieres ejecutar sin Docker:

1. **Instalar dependencias:**

    ```bash
    make install
    ```

2. **Ejecutar servicios (en terminales separadas):**

    ```bash
    make api        # Terminal 1: Inicia la API
    make dashboard  # Terminal 2: Inicia el dashboard
    ```

3. **Acceder a las interfaces:**

    * Dashboard: http://localhost:8501
    * API: http://localhost:8000/docs

**Nota:** AsegÃºrate de tener el archivo `final_model.pkl` en la raÃ­z del proyecto antes de ejecutar la API o el dashboard.

---

## ğŸ§  Dashboard & API

El sistema ofrece dos formas de interactuar con el modelo:

### 1. Dashboard Interactivo (Streamlit)

Interfaz web simple y visual:

* **Formulario de datos:** Campos para introducir el perfil del cliente
* **PredicciÃ³n en tiempo real:** Muestra la probabilidad de impago
* **Explicabilidad con SHAP:** GrÃ¡ficos que muestran quÃ© variables (edad, saldo, historial crediticio) influyen mÃ¡s en la decisiÃ³n

### 2. API REST (FastAPI)

Endpoint programÃ¡tico para integraciones:

* **Endpoint `/predict`:** Recibe el perfil del cliente en formato JSON y devuelve la predicciÃ³n
* **ValidaciÃ³n automÃ¡tica:** Verifica que los datos de entrada sean correctos
* **DocumentaciÃ³n interactiva:** Interfaz Swagger en `/docs` para probar la API directamente desde el navegador

---

## âš™ï¸ MetodologÃ­a de Data Science

### 1. IngenierÃ­a de Datos:

* **Dataset:** German Credit Data con informaciÃ³n de clientes bancarios
* **Limpieza:** Mapeo de variables categÃ³ricas codificadas (ej: A11 â†’ "Saldo Negativo")
* **Preprocesamiento:** Pipeline con escalado para variables numÃ©ricas y codificaciÃ³n One-Hot para categÃ³ricas

### 2. Modelado:

* **ValidaciÃ³n Cruzada Anidada:** Evita sobreajuste al seleccionar el mejor modelo
* **Modelos evaluados:** Logistic Regression, KNN, Random Forest, XGBoost
* **OptimizaciÃ³n:** BÃºsqueda bayesiana de hiperparÃ¡metros con Optuna maximizando F1-Score
* **Tracking:** Todos los experimentos registrados en MLflow

### 3. Interpretabilidad:

* **SHAP Values:** Explica cada predicciÃ³n mostrando quÃ© variables son mÃ¡s importantes
* **Transparencia:** Permite entender por quÃ© el modelo toma cada decisiÃ³n

---

## ğŸ“Š Resultados

**XGBoost** fue seleccionado como modelo de producciÃ³n por su excelente desempeÃ±o:

* **Manejo de desbalanceo de clases:** Penaliza correctamente los falsos negativos (clientes de alto riesgo)
* **Captura de relaciones no lineales:** Detecta patrones complejos entre variables
* **Robustez:** Rendimiento consistente en validaciÃ³n cruzada

![ComparaciÃ³n de modelos mediante ValidaciÃ³n Cruzada Anidada](images/ncv_model_comparison.png)

Todos los experimentos estÃ¡n disponibles en MLflow con mÃ©tricas, parÃ¡metros y artefactos versionados.

---

## âœ’ï¸ Autor

**Juan Pedro GarcÃ­a Sanz**

* **GitHub:** [@Juanpeg1729](https://github.com/Juanpeg1729)
* **LinkedIn:** [Juan Pedro GarcÃ­a Sanz](https://www.linkedin.com/in/juanpedrogarciasanz)
